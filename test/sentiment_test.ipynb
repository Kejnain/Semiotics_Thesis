{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\TTill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\TTill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file path: c:\\Users\\TTill\\Semiotics_Thesis-1\\models\\improved_sentiment_model.pkl\n",
      "Model loaded successfully!\n",
      "Error while predicting sentiment: unsupported operand type(s) for *: 'csr_matrix' and 'csr_matrix'\n",
      "Failed to generate sentiment vector.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def processText(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "models = 'models'\n",
    "parent = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "path = os.path.join(parent, models, 'improved_sentiment_model.pkl')\n",
    "\n",
    "print(f\"Model file path: {path}\")\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    print(\"Error: Model file does not exist.\")\n",
    "else:\n",
    "    try:\n",
    "        with open(path, 'rb') as sentiment_model_file:\n",
    "            sentiment_model = pickle.load(sentiment_model_file)\n",
    "        print(\"Model loaded successfully!\")\n",
    "\n",
    "    except EOFError:\n",
    "        print(\"Error: Ran out of input while loading the model. The model file might be empty or corrupted.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "\n",
    "def get_sentiment_vector(sentiment_model, text_input):\n",
    "    try:\n",
    "        processed_text = processText(text_input)\n",
    "        \n",
    "        if sentiment_model is None:\n",
    "            print(\"Error: Sentiment model is not loaded. Please ensure the model is properly loaded.\")\n",
    "            return None\n",
    "\n",
    "        sentiment_scores = sentiment_model.predict_proba([processed_text])  \n",
    "\n",
    "        print(f\"Type of sentiment_scores: {type(sentiment_scores)}\")\n",
    "\n",
    "        sentiment_vector = []\n",
    "        for label_scores in sentiment_scores[0]:  \n",
    "            dense_scores = label_scores.toarray() if hasattr(label_scores, 'toarray') else label_scores\n",
    "            sentiment_vector.extend(dense_scores.flatten())\n",
    "\n",
    "        sentiment_vector = np.array(sentiment_vector)\n",
    "        \n",
    "        sentiment_vector = sentiment_vector / sentiment_vector.sum() * 100\n",
    "        \n",
    "        return sentiment_vector\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error while predicting sentiment: {e}\")\n",
    "        return None\n",
    "\n",
    "input_text = input(\"Enter text for sentiment analysis: \")\n",
    "if 'sentiment_model' in locals(): \n",
    "    sentiment_vector = get_sentiment_vector(sentiment_model, input_text)\n",
    "\n",
    "    if sentiment_vector is not None:\n",
    "        print(\"Sentiment Vector:\", sentiment_vector)\n",
    "    else:\n",
    "        print(\"Failed to generate sentiment vector.\")\n",
    "else:\n",
    "    print(\"Sentiment model is not loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the trained model...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'improved_sentiment_model.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 69\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo significant emotions detected.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 69\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 48\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading the trained model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     47\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimproved_sentiment_model.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 48\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading emotion labels...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     51\u001b[0m emotion_labels \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgoemotions.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m7\u001b[39m:]  \n",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(filepath):\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m model_file:\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mload(model_file)\n",
      "File \u001b[1;32mc:\\Users\\TTill\\anaconda3\\envs\\keji\\lib\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'improved_sentiment_model.pkl'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def load_model(filepath):\n",
    "    with open(filepath, 'rb') as model_file:\n",
    "        return pickle.load(model_file)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    stopwords = {'a', 'an', 'and', 'are', 'as', 'at', 'be', 'by', 'for', 'from', 'has',\n",
    "                 'he', 'in', 'is', 'it', 'its', 'of', 'on', 'that', 'the', 'to', 'was',\n",
    "                 'were', 'will', 'with'}\n",
    "    tokens = [word for word in text.split() if word not in stopwords]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def predict_emotions_with_confidence(text, model, emotion_labels):\n",
    "    \n",
    "    processed_text = preprocess_text(text)\n",
    "    \n",
    "    base_estimators = model.named_steps['classifier'].estimators_\n",
    "\n",
    "    X_processed = model.named_steps['tfidf'].transform([processed_text])\n",
    "    X_processed = model.named_steps['scaler'].transform(X_processed)\n",
    "    \n",
    "    emotion_confidence_vector = np.zeros(len(emotion_labels))\n",
    "    \n",
    "    for idx, (emotion, estimator) in enumerate(zip(emotion_labels, base_estimators)):\n",
    "        try:\n",
    "            proba = estimator.predict_proba(X_processed)[0][1]\n",
    "            if proba > 0.1:  \n",
    "                emotion_confidence_vector[idx] = proba\n",
    "        except (AttributeError, IndexError):\n",
    "            prediction = estimator.predict(X_processed)[0]\n",
    "            if prediction == 1:\n",
    "                emotion_confidence_vector[idx] = 1.0\n",
    "    \n",
    "    return emotion_confidence_vector\n",
    "\n",
    "def main():\n",
    "    print(\"Loading the trained model...\")\n",
    "    model_path = 'improved_sentiment_model.pkl'\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    print(\"Loading emotion labels...\")\n",
    "    emotion_labels = pd.read_csv('goemotions.csv').columns[7:]  \n",
    "\n",
    "    print(\"\\nType 'exit' to quit the program.\")\n",
    "    while True:\n",
    "        user_input = input(\"\\nEnter a text to analyze emotions: \")\n",
    "        if user_input.lower() == 'exit':\n",
    "            print(\"Exiting...\")\n",
    "            break\n",
    "\n",
    "        emotion_scores_vector = predict_emotions_with_confidence(user_input, model, emotion_labels)\n",
    "        \n",
    "        if np.any(emotion_scores_vector):\n",
    "            print(\"\\nPredicted emotion vector (confidence scores):\")\n",
    "            print(emotion_scores_vector)\n",
    "        else:\n",
    "            print(\"No significant emotions detected.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keji",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
